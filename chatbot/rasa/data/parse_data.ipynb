{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "import ruamel.yaml\n",
    "yaml = ruamel.yaml.YAML()\n",
    "\n",
    "from processing import processing\n",
    "\n",
    "from importlib import reload\n",
    "reload(processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# define paths\n",
    "\n",
    "home = os.getenv(\"PROJ_HOME\")\n",
    "\n",
    "articles_filepath = os.path.join(home, \"chatbot/data/chatbot_knowledgebase/subject_matter/article_data.json\")\n",
    "exhibits_filepath = os.path.join(home, \"chatbot/data/chatbot_knowledgebase/institutional/exhibits.json\")\n",
    "galleries_filepath = os.path.join(home, \"chatbot/data/chatbot_knowledgebase/institutional/galleries.json\")\n",
    "\n",
    "lookup_directory = os.path.join(home, \"chatbot/rasa/data/nlu/lookups\")\n",
    "synonym_directory = os.path.join(home, \"chatbot/rasa/data/nlu/synonyms\")\n",
    "intent_templates_directory = os.path.join(home, \"chatbot/rasa/data/txt_files/templates\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# remove extra spaces and punctuation\n",
    "\n",
    "def remove_punc(text):\n",
    "    text_sans_punc = processing.preprocess(text,\n",
    "                                           accented_chars=False,\n",
    "                                           contractions=False,\n",
    "                                           convert_num=False,\n",
    "                                           lemmatization=False,\n",
    "                                           stop_words=False)\n",
    "    return text_sans_punc\n",
    "\n",
    "# fill intent template with given entity having index ind\n",
    "\n",
    "def fill_template(entity, templates, ind):\n",
    "    num_templates = len(templates)\n",
    "    template = templates[ind % num_templates]\n",
    "    anno_filled = \"[\" + entity + \"]\"\n",
    "    anno_empty = re.search(anno_pattern, template)\n",
    "    filled = template.replace(anno_empty.group(0), anno_filled)\n",
    "    return filled\n",
    "\n",
    "# functions for converting a list to a yaml string literal\n",
    "\n",
    "def literalize_list(v):\n",
    "    assert isinstance(v, list)\n",
    "    buf = io.StringIO()\n",
    "    yaml.dump(v, buf)\n",
    "    return ruamel.yaml.scalarstring.LiteralScalarString(buf.getvalue())\n",
    "\n",
    "def transform_value(d, key, transformation):\n",
    "    if isinstance(d, dict):\n",
    "        for k, v in d.items():\n",
    "            if k == key:\n",
    "                d[k] = transformation(v)\n",
    "            else:\n",
    "                transform_value(v, key, transformation)\n",
    "    elif isinstance(d, list):\n",
    "        for elem in d:\n",
    "            transform_value(elem, key, transformation)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "# get list of unique subjects\n",
    "\n",
    "with open(articles_filepath, \"r\") as f:\n",
    "    articles = json.load(f)\n",
    "\n",
    "subjects = []\n",
    "for article in articles:\n",
    "    subjects.append(article[\"title\"])\n",
    "    subjects += article[\"aliases\"]\n",
    "subjects = list(set(subjects))\n",
    "\n",
    "paren_pattern = r\"(\\(.*?\\))|(\\(.*)\"\n",
    "\n",
    "clean_subjects = []\n",
    "for subject in subjects:\n",
    "    this_subject = subject.split(\":\")[0]\n",
    "    this_subject = re.sub(paren_pattern, \"\", this_subject)\n",
    "    parts = this_subject.split(\".\")\n",
    "    num_parts = len(parts)\n",
    "    this_subject = \"\"\n",
    "    for count, part in enumerate(parts):\n",
    "        if len(part) <= 4 and count < num_parts - 1:\n",
    "            this_subject += part + \".\"\n",
    "        else:\n",
    "            this_subject += part\n",
    "            break\n",
    "    clean_subjects.append(this_subject.strip())\n",
    "\n",
    "num_subjects = len(clean_subjects)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "# get list of exhibit names, including aliases\n",
    "\n",
    "with open(exhibits_filepath, \"r\") as f:\n",
    "    exhibit_data = json.load(f)\n",
    "\n",
    "exhibits = []\n",
    "exhibit_synonyms = {}\n",
    "\n",
    "for item in exhibit_data:\n",
    "    title = remove_punc(item[\"title\"])\n",
    "    aliases = [remove_punc(alias) for alias in item[\"aliases\"]]\n",
    "    exhibits.append(title)\n",
    "    exhibits += aliases\n",
    "    these_aliases = [title] + aliases\n",
    "    if item[\"id\"] in exhibit_synonyms.keys():\n",
    "        exhibit_synonyms[item[\"id\"]] += these_aliases\n",
    "    else:\n",
    "        exhibit_synonyms[item[\"id\"]] = these_aliases\n",
    "\n",
    "clean_exhibits = list(set(exhibits))\n",
    "\n",
    "num_exhibits = len(exhibit_synonyms)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "# get list of gallery names, including aliases (TBA)\n",
    "\n",
    "with open(galleries_filepath, \"r\") as f:\n",
    "    gallery_data = json.load(f)\n",
    "\n",
    "galleries = []\n",
    "\n",
    "for item in gallery_data:\n",
    "    galleries.append(item[\"title\"])\n",
    "\n",
    "clean_galleries = list(set(galleries))\n",
    "\n",
    "num_galleries = len(clean_galleries)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "# export entity lists found above to yaml lookup files\n",
    "\n",
    "entity_names = {\n",
    "    \"subject\": clean_subjects,\n",
    "    \"exhibit\": clean_exhibits,\n",
    "    \"gallery\": clean_galleries\n",
    "}\n",
    "\n",
    "for entity in entity_names.keys():\n",
    "    lookup_dict = {\n",
    "            \"version\": \"3.1\",\n",
    "            \"nlu\": [{\"lookup\": entity, \"examples\": entity_names[entity]}]\n",
    "        }\n",
    "\n",
    "    transform_value(lookup_dict, 'examples', literalize_list)\n",
    "\n",
    "    filepath = os.path.join(lookup_directory, entity + \".yml\")\n",
    "    with open(filepath, \"w\") as f:\n",
    "        yaml.dump(lookup_dict, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "# export exhibit alias names to yaml file for synonym matching\n",
    "\n",
    "synonym_dict = {\n",
    "            \"version\": \"3.1\",\n",
    "            \"nlu\": []\n",
    "        }\n",
    "\n",
    "for exhibit_id in exhibit_synonyms.keys():\n",
    "    synonym_dict[\"nlu\"].append({\"synonym\": exhibit_id, \"examples\": exhibit_synonyms[exhibit_id]})\n",
    "\n",
    "transform_value(synonym_dict, 'examples', literalize_list)\n",
    "\n",
    "filepath = os.path.join(synonym_directory, \"exhibits.yml\")\n",
    "with open(filepath, \"w\") as f:\n",
    "    yaml.dump(synonym_dict, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "# generate yaml nlu files containing annotated intents\n",
    "\n",
    "anno_pattern = r\"\\[.*?\\]\"\n",
    "\n",
    "for infile in os.listdir(intent_templates_directory):\n",
    "    infilepath = os.path.join(intent_templates_directory, infile)\n",
    "\n",
    "    nonanno_examples = []\n",
    "    anno_examples = []\n",
    "    with open(infilepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            if re.search(anno_pattern, line):\n",
    "                anno_examples.append(line.strip(\"\\n\"))\n",
    "            else:\n",
    "                nonanno_examples.append(line.strip(\"\\n\"))\n",
    "\n",
    "    num_templates =  len(anno_examples)\n",
    "\n",
    "    intent = infile.split(\"_template\")[0]\n",
    "    if \"explanation\" in intent:\n",
    "        entity_list = clean_subjects\n",
    "        num_entities = num_subjects\n",
    "        dir_out = os.path.join(home, \"rasa/data/nlu/subjects\")\n",
    "    elif \"exhibit\" in intent:\n",
    "        entity_list = clean_exhibits\n",
    "        num_entities = num_exhibits\n",
    "        dir_out = os.path.join(home, \"rasa/data/nlu/exhibits\")\n",
    "    elif \"gallery\" in intent:\n",
    "        entity_list = clean_galleries\n",
    "        num_entities = num_galleries\n",
    "        dir_out = os.path.join(home, \"rasa/data/nlu/galleries\")\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    rand_entities = []\n",
    "    for _ in range(5):\n",
    "        rand_entities.append(random.choice(entity_list))\n",
    "\n",
    "\n",
    "    if (delta := num_templates - num_templates) > 0:\n",
    "        sampled_entities = []\n",
    "        for _ in range(delta):\n",
    "            sampled_entities += random.choice(entity_list)\n",
    "        entity_list += sampled_entities\n",
    "\n",
    "    examples = nonanno_examples\n",
    "    for count, entity in enumerate(entity_list):\n",
    "        example = fill_template(entity=entity, templates=anno_examples, ind=count)\n",
    "        examples.append(example)\n",
    "\n",
    "    intent_dict = {\n",
    "        \"version\": \"3.1\",\n",
    "        \"nlu\": [{\"intent\": intent, \"examples\": examples}]\n",
    "    }\n",
    "\n",
    "    transform_value(intent_dict, 'examples', literalize_list)\n",
    "    outfile = intent + \".yml\"\n",
    "    outfilepath = os.path.join(dir_out, outfile)\n",
    "\n",
    "    with open(outfilepath, \"w\") as f:\n",
    "        yaml.dump(intent_dict, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
